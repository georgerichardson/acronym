{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f279362c-a405-49ce-8818-7ef4f52ffb9e",
   "metadata": {},
   "source": [
    "# Embedding Project Abstracts and Acronyms using Colab\n",
    "\n",
    "1. Upload all project data from `inputs/data/cordis/<fp>/project.csv` and acronym data from `outputs/data/cordis/<fp>/acronyms.csv` to a directories following the same structure.\n",
    "2. Enter values for the `LOAD_DIR` and `SAVE_DIR` variables in the cell below. These should be subdirectories within `DRIVE_DIR`. They can be the same.\n",
    "3. Run all of the cells below.\n",
    "4. Download outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34771cd4-fbf8-427c-a4d1-9947a7b652be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import regex\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import Optional, List, Sequence\n",
    "from google.colab import drive\n",
    "\n",
    "\n",
    "TEST = True\n",
    "\n",
    "ENCODER_NAME = \"all-MiniLM-L12-v2\"\n",
    "FRAMEWORK_PROGRAMMES = [\"fp1\", \"fp2\", \"fp3\", \"fp3\", \"fp4\", \"fp5\", \"fp6\", \"fp7\", \"h2020\"]\n",
    "\n",
    "DRIVE_DIR = \"/content/drive\"\n",
    "LOAD_DIR = # e.g. MyDrive/acronym\n",
    "SAVE_DIR = # e.g. MyDrive/acronym\n",
    "\n",
    "\n",
    "drive.mount(DRIVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb708b-abb1-4b60-a1b8-ded78cfeeb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_encoder(model_name: str) -> SentenceTransformer:\n",
    "    \"\"\"Fetches a sentence transformer model.\"\"\"\n",
    "    return SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "def embed(\n",
    "    model: SentenceTransformer, texts: Sequence, chunk_size: Optional[int] = None\n",
    ") -> np.array:\n",
    "    \"\"\"Embeds a sequence of texts using a sentence transformer.\n",
    "\n",
    "    Args:\n",
    "        model: A sentence transformer.\n",
    "        texts: A sequence of texts.\n",
    "        chunk_size: Splits the texts into chunks to be embedded sequentially.\n",
    "            Useful for breaking up large sequences which might exceed memory.\n",
    "    \"\"\"\n",
    "    return encoder.encode(texts)\n",
    "\n",
    "\n",
    "def remove_mentions(acronyms: Sequence[str], abstracts: Sequence[str]) -> List[str]:\n",
    "    \"\"\"Removes close and exact matches of the acronym from the abstract (ignores case).\n",
    "\n",
    "    Args:\n",
    "        acronyms (Sequence[str]): Project acronyms.\n",
    "        abstracts (Sequence[str]): Project abstracts.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Modified abstracts.\n",
    "    \"\"\"\n",
    "    abstracts_mod = []\n",
    "    for acronym, abstract in zip(acronyms, abstracts):\n",
    "        r = rf\"({acronym}){{s<=2,i<=1,d<=2,e<=2}}\"\n",
    "        matches = regex.findall(r, abstract, flags=regex.IGNORECASE)\n",
    "        for match in matches:\n",
    "            abstract = abstract.replace(match, \" \")\n",
    "        abstracts_mod.append(abstract)\n",
    "    return abstracts_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886d509-4185-47c5-8cf3-e172db1479ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fp in FRAMEWORK_PROGRAMMES:\n",
    "    n = 50 if TEST else None\n",
    "    projects_fp = pd.read_csv(f\"{DRIVE_DIR}/{LOAD_DIR}/{fp}/project.csv\").iloc[:n]\n",
    "    acronyms_fp = pd.read_csv(f\"{DRIVE_DIR}/{LOAD_DIR}/{fp}/acronyms.csv\").iloc[:n]\n",
    "\n",
    "    abstracts_modified = remove_mentions(\n",
    "        acronyms_fp[\"acronym\"],\n",
    "        projects_fp[\"objective\"].fillna(\"\"),\n",
    "    )\n",
    "\n",
    "    encoder = fetch_encoder(ENCODER_NAME)\n",
    "\n",
    "    abstract_embeddings_fp = embed(encoder, abstracts_modified)\n",
    "    acronym_embeddings_fp = embed(encoder, acronyms_fp[\"acronym\"].tolist())\n",
    "\n",
    "    np.save(\n",
    "        f\"{DRIVE_DIR}/{SAVE_DIR}/{fp}/abstract_embeddings\",\n",
    "        abstract_embeddings_fp,\n",
    "    )\n",
    "    np.save(\n",
    "        f\"{DRIVE_DIR}/{SAVE_DIR}/{fp}/acronym_embeddings\",\n",
    "        acronym_embeddings_fp,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "comment_magics": true
  },
  "kernelspec": {
   "display_name": "acyronym",
   "language": "python",
   "name": "acyronym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
